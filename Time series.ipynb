{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Turn on equation numbering first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "  TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book is about learning some theory basics on time series and their analysis. _Stationary_ time series play an important role in time series analysis. Therefore, let's start with a definition: a time series $\\{y_t\\}$ is _covariance stationary_ (or _weakly stationary_) if its expectation value and (auto-)covariances are time independent:\n",
    "\\begin{align}\n",
    "\\mathrm{E}[y_t] &= \\mu \\label{eq:stationary1} \\\\\n",
    "\\mathrm{E}[(y_t - \\mu)(y_{t-j} - \\mu)] &= \\gamma_j \\label{eq:stationary2}\n",
    "\\end{align}\n",
    "For the rest of this notebook, we will refer to _covariance stationary_ using the short-hand (but somehow imprecise) _stationary_.\n",
    "\n",
    "As an example consider a simple random walk model\n",
    "\\begin{equation}\n",
    "y_t = y_{t-1} + u_t \\label{eq:rw}\n",
    "\\end{equation}\n",
    "where $u_t$ is Gaussian white noise ($u_t \\sim \\mathcal{N}(0,\\sigma^2)$). For simplicity we define $y_0 = 0$ which simplifies \\eqref{eq:rw} to \n",
    "\\begin{equation}\n",
    "y_t = \\sum_{i=1}^t u_t. \\label{eq:rw_simple}\n",
    "\\end{equation}\n",
    "\n",
    "So let's start with generating an example time series for 100 time steps and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sample(y,samples= 5):\n",
    "    \"\"\"\n",
    "    input: y       ... ensemble of timeseries as np.array with shape (timesteps,ensemble_size)\n",
    "           samples ... number of individual time series to plot\n",
    "    \"\"\"\n",
    "    plt.plot(y[:,:samples])\n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('$y_t$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timesteps = 100\n",
    "# set mean and variance of the noise\n",
    "mean = 0\n",
    "var = 1\n",
    "# generate the Gaussian white noise\n",
    "noise = np.random.normal(mean,sqrt(var),size=timesteps)\n",
    "# construct and plot the time series\n",
    "rw = np.cumsum(noise)\n",
    "plot_sample(rw.add,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question now is whether time series generated by such a model are _stationary_. In order to answer this question, we need to check the conditions \\eqref{eq:stationary1} and \\eqref{eq:stationary2} outlined above. This can be done by generating an ensemble of time series for this model and evaluate the mean and the (auto-)covariances as function of the timestep $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble_size = 1000\n",
    "# generate an ensemble of the Gaussian white noise\n",
    "noise = np.random.normal(mean,sqrt(var),size=(timesteps,ensemble_size))\n",
    "# summing along the first axis yields the different time series\n",
    "rw = np.cumsum(noise,axis=0)\n",
    "# make an example plot for the first 5 time series of the ensemble\n",
    "plt.plot(rw[:,:5])\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$y_t$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an ensemble of time series generated by this model, we can test the conditions for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the mean and covariances as function of the time\n",
    "# this time we average of the second axis which corresponds to the different time series in the ensemble\n",
    "means = np.mean(rw,axis=1)\n",
    "# calculate variance from ensemble (correct for bias)\n",
    "vars = np.var(rw,axis=1,ddof=1)\n",
    "_,(ax1,ax2) = plt.subplots(nrows = 2, sharex=True,figsize=(8,8))\n",
    "ax1.plot(means)\n",
    "ax1.set_xlabel('$t$')\n",
    "ax1.set_ylabel('$\\mathrm{E}[y_t]$')\n",
    "ax2.plot(vars)\n",
    "ax2.set_xlabel('$t$')\n",
    "ax2.set_ylabel('$\\sigma^2(y_t)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see the expected values for $y_t$ are rather stable while the variance $\\sigma^2 (y_t)$ is increasing linearly with $t$. This can easily be seen from equation \\eqref{eq:rw_simple} above since $$\\sigma^2 (y_t) = \\sum_{i=1}^t \\sigma^2 (u_t) = t \\sigma^2.$$\n",
    "Therefore, random walk models do **not** produce stationary time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Moving average processes of order $q$_ form another class of time series and are called MA(q). They are defined by\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = \\mu + u_t + \\sum_{i=1}^q \\theta_i u_{t - i} = \\mu + \\theta^\\intercal u \\label{eq:maq}\n",
    "\\end{equation}\n",
    "\n",
    "with $\\theta^\\intercal = \\left(\\theta_0 = 1, \\theta_1 \\dots \\theta_q \\right)$ and $u = \\left(u_t, u_{t-1} \\dots u_{t-q} \\right)^\\intercal$ where $\\mu$ and $\\theta_i$ are constants while $\\{u_t\\}$ is white noise ($\\sim iid(0,\\sigma^2)$). From \\eqref{eq:maq} one can easily derive the expectation value and (auto-)covariances for $y_t$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{E}[y_t] &= \\mu \\\\\n",
    "\\gamma_0 &= \\sigma^2 \\sum_{i=0}^q \\theta_i^2 \\\\\n",
    "\\gamma_j &= \\begin{cases} \\sigma^2 \\sum_{i=0}^{q-j} \\theta_i \\theta_{i+j} & \\text{if } 1 \\le j \\le q \\\\ 0 & \\text{if } j > q\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Since these are all time-independent, MA(q) models generate stationary time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MA_Q(mu,theta,q,var,timesteps,ensemble_size):\n",
    "    \"\"\"\n",
    "    generate MA(q) time series\n",
    "    \n",
    "    input: mu            ... mean of time series\n",
    "           theta         ... coefficient vector (including theta_0 = 1)\n",
    "           q             ... order of MA process\n",
    "           var           ... variance of white noise\n",
    "           timesteps     ... number of time steps to generate the process for\n",
    "           ensemble_size ... number of time series to generate\n",
    "           \n",
    "    returns: y     ... ensemble of MA(q) time series with shape (timesteps, ensemble_size)\n",
    "             gamma ... vector (auto-)covariances up to j = q\n",
    "    \"\"\"\n",
    "    y = np.zeros((timesteps,ensemble_size))\n",
    "    # account for theta_0\n",
    "    ut = np.zeros((q+1,ensemble_size))\n",
    "    for t in np.arange(timesteps):\n",
    "        ut = np.roll(ut,1,axis=0)\n",
    "        ut[0,:] = np.random.normal(0,sqrt(var),size=(1,ensemble_size))\n",
    "        y[t,:] = mu + np.dot(theta,ut)\n",
    "    \n",
    "    # covariance and q autocovariances for lags 1...q\n",
    "    covars = np.zeros(q+1)\n",
    "    covars[0] = np.sum(theta**2)\n",
    "    for j in np.arange(1,q+1):\n",
    "        covars[j] = np.sum([theta[a] * theta[a-j] for a in np.arange(j,q+1)])\n",
    "    covars *= var\n",
    "    return y,covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set coefficients (up to 6) and add theta_0 = 1 at the beginning\n",
    "thetas = np.random.rand(6)\n",
    "thetas = np.insert(thetas,0,1)\n",
    "\n",
    "# get an ensemble of MA(6) time series with the theortical values for the mean expectation and autocovariances\n",
    "ma6, gamma = MA_Q(1.7,thetas,6,1,timesteps,ensemble_size)\n",
    "# make an example plot for the first 5 time series of the ensemble\n",
    "plt.plot(ma6[:,:5])\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$y_t$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the mean as function of the time\n",
    "mu = 1.7\n",
    "means = np.mean(ma6,axis=1)\n",
    "# calculate auto-covariance for certain lags from ensemble\n",
    "lags = np.arange(7)\n",
    "covars = np.vstack([np.hstack([np.cov(ma6[t,:],ma6[t-j,:],ddof=1)[0,1] for t in np.arange(timesteps)]) for j in lags])\n",
    "_,axes = plt.subplots(ncols = 2, nrows = 4, sharex=True,figsize=(12,9))\n",
    "axes = axes.flatten()\n",
    "axes[0].plot(means)\n",
    "axes[0].hlines(mu,0,100,'r')\n",
    "axes[0].set_xlabel('$t$')\n",
    "axes[0].set_ylabel('$\\mathrm{E}[y_t]$')\n",
    "for i in np.arange(1,len(lags)+1):\n",
    "    axes[i].plot(covars[i-1,:])\n",
    "    axes[i].hlines(gamma[i-1],0,100,'r')\n",
    "    axes[i].set_xlabel('$t$')\n",
    "    axes[i].set_ylabel('$\\gamma_%d$' % lags[i-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots nicely illustrate that MA(q) processes are covariance-stationary.\n",
    "\n",
    "_Autoregressive processes of order p_ are yet another class of time series models denoted AR(p). They are defined by\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = c + \\sum_{i=1}^p \\phi_i y_{t-i} + u_t \\label{eq:ar}\n",
    "\\end{equation}\n",
    "\n",
    "with $c$, $\\phi_i$ being constants and $\\{u_t\\}$ being again white noise ($\\sim iid(0,\\sigma^2)$). A AR(1) process can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = c + \\phi y_{t-1} + u_t = c \\sum_{i=0}^{t-1} \\phi^i + \\sum_{i=0}^{t-1} \\phi^i u_{t-i} + \\phi^t y_0 \\label{eq:ar1}\n",
    "\\end{equation}\n",
    "\n",
    "where the right-hand side is the MA(t) representation of an AR(1) process. Assuming $|\\phi| < 1$ the effect of the initial condition will decay with time and\n",
    "\n",
    "\\begin{equation}\n",
    "\\lim_{t \\to \\infty} \\phi^t y_0 \\to 0 .\n",
    "\\end{equation}\n",
    "\n",
    "In this case, the time series can be assumed to have started long ago in the past and \\eqref{eq:ar1} simplifies to (using $\\sum_{i=0}^\\infty \\phi^i = \\left( 1 - \\phi \\right)^{-1}$)\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = \\frac{c}{1 - \\phi} + \\sum_{i=0}^\\infty \\phi^i u_{t-i} .\n",
    "\\end{equation}\n",
    "\n",
    "The special case $c= 0$ and $\\phi=1$ is called random walk and was already discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ar_p(c,phi,var,p=3):\n",
    "    \"\"\"\n",
    "    generate AR(p) time series\n",
    "    \n",
    "    returns: y     ... ensemble of time series\n",
    "             mu    ... expectation value\n",
    "             gamma ... (auto-)covariances up to j = q + 1\n",
    "    \"\"\"\n",
    "    y = np.zeros((timesteps,ensemble_size))\n",
    "    tmp = np.zeros((p,ensemble_size))\n",
    "    for t in np.arange(timesteps):\n",
    "        y[t,:] = c + np.dot(phi,tmp) + np.random.normal(0,sqrt(var),size=(1,ensemble_size))\n",
    "        tmp = np.roll(tmp,1,axis=0)\n",
    "        tmp[0,:] = y[t,:]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get an ensemble of AR(6) time series with the theortical values for the mean expectation and autocovariances\n",
    "p = 6\n",
    "phis = np.random.normal(0,0.3,6)\n",
    "print(phis)\n",
    "ar6 = ar_p(0.3,phis,0.7,p)\n",
    "# make an example plot for the first 5 time series of the ensemble\n",
    "plt.plot(ar6[:,:5])\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$y_t$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the mean as function of the time\n",
    "means = np.mean(ar6,axis=1)\n",
    "# calculate auto-covariance for certain lags from ensemble\n",
    "lags = np.arange(7)\n",
    "covars = np.vstack([np.hstack([np.cov(ar6[t,:],ar6[t-j,:],ddof=1)[0,1] for t in np.arange(timesteps)]) for j in lags])\n",
    "_,axes = plt.subplots(ncols = 2, nrows = 4, sharex=True,figsize=(12,9))\n",
    "axes = axes.flatten()\n",
    "axes[0].plot(means)\n",
    "axes[0].hlines(mu,0,100,'r')\n",
    "axes[0].set_xlabel('$t$')\n",
    "axes[0].set_ylabel('$\\mathrm{E}[y_t]$')\n",
    "for i in np.arange(1,len(lags)+1):\n",
    "    axes[i].plot(covars[i-1,:])\n",
    "    axes[i].hlines(gamma[i-1],0,100,'r')\n",
    "    axes[i].set_xlabel('$t$')\n",
    "    axes[i].set_ylabel('$\\gamma_%d$' % lags[i-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acovf\n",
    "print(acovf(ma3[10:,0],unbiased=True)[1])\n",
    "print(acovf(ma3[10:,0] - 10)[1])\n",
    "print(np.cov(ma3[10:-1,0],ma3[11:,0],ddof=0))\n",
    "print((np.correlate(ma3[10:,0]-100,ma3[10:,0]-100,'full')/90)[89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?np.arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
